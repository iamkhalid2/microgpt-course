# The Learning Machine Analogy

## A Machine That Learns From Mistakes

Before we touch any code, let's build an analogy that will carry us through the entire course.

### The Blindfolded Archer

Imagine a blindfolded archer trying to hit a target:

```mermaid
flowchart LR
    A["üèπ Archer<br>(blindfolded)"] -- "shoots" --> B["‚ùå Miss!<br>(too high, too right)"]
    B -- "friend says:<br>aim lower & left" --> C["üéØ Adjusts aim"]
    C -- "shoots again" --> A
```

1. The archer shoots an arrow (makes a **prediction**)
2. A friend tells them: "You were 2 meters too high and 1 meter to the right" (the **loss** ‚Äî how wrong they were)
3. The friend also says: "Aim lower and more to the left" (the **gradient** ‚Äî which direction to adjust)
4. The archer adjusts their aim slightly (the **parameter update**)
5. They shoot again

After hundreds of attempts, the archer is landing arrows near the bullseye ‚Äî *without ever seeing the target*.

!!! tip "Key Insight"

    **This is exactly how neural networks learn.** They never "see" the answer directly ‚Äî they just get told how wrong they were and which direction to adjust.

## Mapping the Analogy to Code

| Analogy | In `microgpt.py` | What it means |
|---------|-------------------|---------------|
| The archer's aim (angle, force) | **Parameters** (lines 74‚Äì90) | Thousands of numbers that control the model's behavior |
| Shooting an arrow | **Forward pass** (lines 163‚Äì168) | Running an input through the model to get a prediction |
| "You missed by X" | **Loss** (line 169) | A single number measuring how bad the prediction was |
| "Aim lower and left" | **Gradients** (line 172) | The direction to nudge each parameter |
| Adjusting aim | **Optimizer** (lines 174‚Äì182) | The rule for how much to nudge |
| Shooting again | **Next training step** (line 153) | Repeating with the next example |

## The Three Phases

The file does three things, in order:

=== "Phase 1: Build the Machine"

    **Lines 1‚Äì144** ‚Äî Build the "archer": the model that takes an input and produces a prediction.

    At this point the parameters are random, so the predictions are garbage.

    ```text
    Input: "emm"  ‚Üí  Model (random parameters)  ‚Üí  Prediction: "q" ‚Üê wrong!
                                                     (should be "a")
    ```

=== "Phase 2: Train the Machine"

    **Lines 146‚Äì184** ‚Äî Show the model thousands of real names. For each one:

    - Let it predict the next character
    - Tell it how wrong it was
    - Adjust parameters slightly

    ```text
    Step    1: loss = 3.8912  (predictions are random garbage)
    Step  100: loss = 2.4561  (starting to learn common patterns)
    Step  300: loss = 1.8234  (getting the hang of it)
    Step  500: loss = 1.5012  (reasonably good at predicting)
    ```

    The loss going **down** means the model is getting **better**.

=== "Phase 3: Use the Machine"

    **Lines 186‚Äì200** ‚Äî Now that the parameters have been tuned, we can use the model to **generate new names** it has never seen:

    ```text
    sample  1: emma
    sample  2: ariel
    sample  3: kaya
    sample  4: suri
    sample  5: livia
    ```

    These names didn't exist in the training data ‚Äî the model *invented* them by learning the patterns of what makes a name "name-like."

## Why "Everything Else Is Just Efficiency"

!!! quote "Karpathy's claim"

    *"This is the complete algorithm. Everything else is just efficiency."*

What does he mean? This 200-line file contains:

| What | Present in microgpt.py? | What the "real world" adds |
|------|:-----------------------:|---------------------------|
| Tokenization | :white_check_mark: | Faster tokenizers (BPE) with larger vocabularies |
| Autograd | :white_check_mark: | GPU-accelerated autograd (PyTorch/JAX) |
| Transformer architecture | :white_check_mark: | More layers, bigger embeddings, but same structure |
| Attention mechanism | :white_check_mark: | FlashAttention (same math, faster execution) |
| Training loop | :white_check_mark: | Distributed training across thousands of GPUs |
| Adam optimizer | :white_check_mark: | Same optimizer, just parallelized |
| Text generation | :white_check_mark: | Same algorithm with beam search, nucleus sampling |

The **algorithm** is identical. What changes at scale is:

- **Speed:** GPUs instead of Python loops
- **Size:** Billions of parameters instead of thousands
- **Data:** Terabytes of text instead of a names file

But the *logic* ‚Äî embed, attend, predict, measure error, compute gradients, update ‚Äî is the same logic you'll learn in this course.

## The Road Ahead

```mermaid
flowchart TD
    HERE["üìç You are here"] --> M1
    M1["Module 1: How do we get data<br>and turn it into numbers?"] --> M2
    M2["Module 2: How do we automatically<br>find 'which way to nudge'?"] --> M3
    M3["Module 3: What math does the model<br>actually do on the numbers?"] --> M4
    M4["Module 4: How does the<br>training loop work?"] --> M5
    M5["Module 5: How do we<br>generate new text?"] --> DONE
    DONE["‚úÖ You understand the entire file"]
```
